[
["index.html", "CADI 2017 1 Preamble", " CADI 2017 Héctor Corrada Bravo 2017-05-29 1 Preamble Here is where the course notes will be included. "],
["introduction-and-overview.html", "2 Introduction and Overview 2.1 What is Data Science? 2.2 Why Data Science? 2.3 Data Science in Humanities and Social Sciences 2.4 Course organization 2.5 General Workflow", " 2 Introduction and Overview 2.1 What is Data Science? Data science encapsulates the interdisciplinary activities required to create data-centric artifacts and applications that address specific scientific, socio-political, business, or other questions. Let’s look at the constiuent parts of this statement: 2.1.1 Data Measureable units of information gathered or captured from activity of people, places and things. 2.1.2 Specific Questions Seeking to understand a phenomenon, natural, social or other, can we formulate specific questions for which an answer posed in terms of patterns observed, tested and or modeled in data is appropriate. 2.1.3 Interdisciplinary Activities Formulating a question, assessing the appropriateness of the data and findings used to find an answer require understanding of the specific subject area. Deciding on the appropriateness of models and inferences made from models based on the data at hand requires understanding of statistical and computational methods. 2.1.4 Data-centric artifacts and applications Answers to questions derived from data are usually shared and published in meaningful, succint but sufficient, reproducible artifacts (papers, books, movies, comics). Going a step further, interactive applications that let others explore data, models and inferences are great. 2.2 Why Data Science? The granularity, size and accessibility data, comprising both physical, social, commercial and political spheres has exploded in the last decade or more. I keep saying that the sexy job in the next 10 years will be statisticians” Hal Varian, Chief Economist at Google (http://www.nytimes.com/2009/08/06/technology/06stats.html?_r=0) “The ability to take data—to be able to understand it, to process it, to extract value from it, to visualize it, to communicate it—that’s going to be a hugely important skill in the next decades, not only at the professional level but even at the educational level for elementary school kids, for high school kids, for college kids.” “Because now we really do have essentially free and ubiquitous data. So the complimentary scarce factor is the ability to understand that data and extract value from it.” Hal Varian (http://www.mckinsey.com/insights/innovation/hal_varian_on_how_the_web_challenges_managers) 2.3 Data Science in Humanities and Social Sciences Because of the large amount of data produced across many spheres of human social and creative activity, many questions in the humanities and social sciences may be addressed by establishing patterns in data. In the humanities, this can range from unproblematic quesitions of how to dissect a large creative corpora, say music, literature, based on raw characteristics of those works, text, sound and image. To more problematic questions, of analysis of intent, understanding, appreciation and valuation of these creative corpora. In the social sciences, issues of fairness and transparency in the current era of big data are especially problematic. Is data collected representative of population for which inferences are drawn? Are methods employed learning latent unfair factors from ostensibly fair data? These are issues that the research community is now starting to address. In all settings, issues of ethical collection of data, application of models, and deployment of data-centric artifacts are essential to grapple with. Issues of privacy are equally important. 2.4 Course organization This course will cover basics of how to use the R data analysis environment for data science activities in humanities and social science. The general organization of the course will be the following: 2.4.1 Day 1: Introduction and preparation Get ourselved settled with R Formulating a question that can be addressed with data How to get data to address a specific question How to manipulate this data to get to what we need for our question of interest How to visualize this data 2.4.2 Day 2: Use cases Social media analysis: text and network structures Fitting and evaluating regression models in R Text analysis Machine Learning modeling in R Survey analysis Nested models in R 2.4.3 Day 3: Presentation and teaching How to present and publish analysis using R Using R in teaching 2.5 General Workflow The data science activities we will cover are roughly organized into a general workflow that will help us navigate this material. 2.5.1 Defining the goal What is the question/problem? Who wants to answer/solve it? What do they know/do now? How well can we expect to answer/solve it? How well do they want us to answer/solve it? 2.5.2 Data collection and Management What data is available? Is it good enough? Is it enough? What are sensible measurements to derive from this data? Units, transformations, rates, ratios, etc. 2.5.3 Modeling What kind of problem is it? E.g., classification, clustering, regression, etc. What kind of model should I use? Do I have enough data for it? Does it really answer the question? 2.5.4 Model evaluation Did it work? How well? Can I interpret the model? What have I learned? 2.5.5 Presentation Again, what are the measurements that tell the real story? How can I describe and visualize them effectively? 2.5.6 Deployment Where will it be hosted? Who will use it? Who will maintain it? "],
["an-illustrative-analysis.html", "3 An Illustrative Analysis 3.1 Gathering data 3.2 Manipulating the data 3.3 Visualizing the data 3.4 Modeling data 3.5 Visualizing model result 3.6 Abstracting the analysis 3.7 Making analyses accessible 3.8 Summary", " 3 An Illustrative Analysis http://fivethirtyeight.com has a clever series of articles on the types of movies different actors make in their careers: https://fivethirtyeight.com/tag/hollywood-taxonomy/ I’d like to do a similar analysis. Let’s do this in order: Let’s do this analysis for Diego Luna Let’s use a clustering algorithm to determine the different types of movies they make Then, let’s write an application that performs this analysis for any actor and test it with Gael García Bernal Let’s make the application interactive so that a user can change the actor and the number of movie clusters the method learns. For now, we will go step by step through this analysis without showing how we perform this analysis using R. As the course progresses, we will learn how to carry out these steps. 3.1 Gathering data 3.1.1 Movie ratings For this analysis we need to get the movies Diego Luna was in, along with their Rotten Tomatoes ratings. For that we scrape this webpage: https://www.rottentomatoes.com/celebrity/diego_luna. Once we scrape the data from the Rotten Tomatoes website and clean it up, this is part of what we have so far: RATING TITLE CREDIT BOX OFFICE YEAR 85 Rogue One: A Star Wars Story Captain Cassian Andor $532.2M 2016 89 Blood Father Jonah — 2016 82 The Book of Life Manolo — 2014 100 I Stay with You (Me quedo contigo) Actor — 2014 67 Elysium Julio $90.8M 2013 41 Casa de mi padre Raul $5.9M 2012 51 Contraband Gonzalo $66.5M 2012 This data includes, for each of the movies Diego Luna has acted in, the rotten tomatoes rating, the movie title, Diego Luna’s role in the movie, the U.S. domestic gross and the year of release. 3.1.2 Movie budgets and revenue For the movie budgets and revenue data we scrape this webpage: http://www.the-numbers.com/movie/budgets/all This is part of what we have for that table after scraping and cleaning up: release_date movie production_budget domestic_gross worldwide_gross 2009-12-18 Avatar 425 760.50762 2783.9190 2015-12-18 Star Wars Ep. VII: The Force Awakens 306 936.66223 2058.6622 2007-05-24 Pirates of the Caribbean: At World’s End 300 309.42043 963.4204 2015-11-06 Spectre 300 200.07417 879.6209 2012-07-20 The Dark Knight Rises 275 448.13910 1084.4391 2013-07-02 The Lone Ranger 275 89.30212 260.0021 2012-03-09 John Carter 275 73.05868 282.7781 2010-11-24 Tangled 260 200.82194 586.5819 2017-06-21 Transformers: The Last Knight 260 0.00000 0.0000 2007-05-04 Spider-Man 3 258 336.53030 890.8753 This data is for 5361 movies, including its release date, title, production budget, US domestic and worlwide gross earnings. The latter three are in millions of U.S. dollars. One thing we might want to check is if the budget and gross entries in this table are inflation adjusted or not. To do this, we can make a plot of domestic gross, which we are using for the subsequent analyses. ## Loading required package: methods ## ## Attaching package: &#39;lubridate&#39; ## The following object is masked from &#39;package:base&#39;: ## ## date Although we don’t know for sure, since the source of our data does not state this specifically, it looks like the domestic gross measurement is inflation adjusted since average gross is stable across years. 3.2 Manipulating the data Next, we combine the datasets we obtained to get closer to the data we need to make the plot we want. We combine the two datasets using the movie title, so that the end result has the information in both tables for each movie. RATING TITLE CREDIT BOX OFFICE YEAR release_date production_budget domestic_gross worldwide_gross 85 Rogue One: A Star Wars Story Captain Cassian Andor $532.2M 2016 2016-12-16 200.0 532.17732 1050.98849 82 The Book of Life Manolo — 2014 2014-10-17 50.0 50.15154 97.65154 67 Elysium Julio $90.8M 2013 2013-08-09 120.0 93.05012 286.19209 51 Contraband Gonzalo $66.5M 2012 2012-01-13 25.0 66.52800 98.40685 94 Milk Jack Lira $31.8M 2008 2008-11-26 20.0 31.84130 57.29337 69 Criminal Rodrigo $0.8M 2004 2016-04-15 31.5 14.70870 38.77126 61 The Terminal Enrique Cruz $77.1M 2004 2004-06-18 75.0 77.07396 218.67396 79 Open Range Button $58.3M 2003 2003-08-15 26.0 58.33125 68.61399 76 Frida Alejandro Gomez $25.7M 2002 2002-10-25 12.0 25.88500 56.13124 3.3 Visualizing the data Now that we have the data we need, we can make a plot: Figure 3.1: Ratings and U.S. Domestic Gross of Diego Luna’s movies. We see that there is one clear outlier in Diego Luna’s movies, which probably is the one Star Wars movie he acted in. The remaining movies could potentially be grouped into two types of movies, those with higher rating and those with lower ratings. 3.4 Modeling data We can use a clustering algorithm to partition Diego Luna’s movies. We can use the data we obtained so far and see if the k-means clustering algorithm partitions these movies into three sensible groups using the movie’s rating and domestic gross. Let’s see how the movies are grouped: TITLE RATING domestic_gross cluster Rogue One: A Star Wars Story 85 532.17732 1 The Book of Life 82 50.15154 2 Milk 94 31.84130 2 Criminal 69 14.70870 2 Frida 76 25.88500 2 Elysium 67 93.05012 3 Contraband 51 66.52800 3 The Terminal 61 77.07396 3 Open Range 79 58.33125 3 3.5 Visualizing model result Let’s remake the same plot as before, but use color to indicate each movie’s cluster assignment given by the k-means algorithm. The algorithm did make the Star Wars movie it’s own group since it’s so different that the other movies. The grouping of the remaining movies is not as clean. To make the plot and clustering more interpretable, let’s annotate the graph with some movie titles. In the k-means algorithm, each group of movies is represented by an average rating and an average domestic gross. What we can do is find the movie in each group that is closest to the average and use that movie title to annotate each group in the plot. Roughly, movies are clustered into Star Wars and low vs. high rated movies. The latter seem to have some difference in domestic gross. For example, movies like “The Terminal” have lower rating but make slightly more money than movies like “Frida”. We could use statistical modeling to see if that’s the case, but will skip that for now. Do note also, that the clustering algorithm we used seems to be assigning one of the movies incorrectly, which warrants further investigation. 3.6 Abstracting the analysis While not a tremendous success, we decide we want to carry on with this analysis. We would like to do this for other actors’ movies. One of the big advantages of using R is that we can write a piece of code that takes an actor’s name as input, and reproduces the steps of this analysis for that actor. We call these functions, we’ll see them and use them a lot in this course. For our analysis, this function must do the following: Scrape movie ratings from Rotten Tomatoes Clean up the scraped data Join with the budget data we downloaded previously Perform the clustering algorithm Make the final plot With this in mind, we can write functions for each of these steps, and then make one final function that puts all of these together. For instance, let’s write the scraping function. It will take an actor’s name and output the scraped data. Let’s test it with Gael García Bernal: RATING TITLE CREDIT BOX OFFICE YEAR 30% Salt and Fire Dr. Fabio Cavani — 2017 75% You’re Killing Me Susana (Me estás matando Susana) Eligio — 2017 94% Neruda Oscar Peluchonneau $1M 2016 Good start. We can then write functions for each of the steps we did with Diego Luna before. Then put all of these steps into one function that calls our new functions to put all of our analysis together: We can test this with Gael García Bernal analyze_actor(&quot;Gael Garcia Bernal&quot;) 3.7 Making analyses accessible Now that we have written a function to analyze an actor’s movies, we can make these analyses easier to produce by creating an interactive application that wraps our new function. The shiny R package makes creating this type of application easy. 3.8 Summary In this analysis we saw examples of the common steps and operations in a data analysis: Data ingestion: we scraped and cleaned data from publicly accessible sites Data manipulation: we integrated data from multiple sources to prepare our analysis Data visualization: we made plots to explore patterns in our data Data modeling: we made a model to capture the grouping patterns in data automatically, using visualization to explore the results of this modeling Publishing: we abstracted our analysis into an application that allows us and others to perform this analysis over more datasets and explore the result of modeling using a variety of parameters "],
["setting-up-r.html", "4 Setting up R 4.1 Setting up R 4.2 Setting up Rstudio 4.3 A first look at Rstudio 4.4 R packages 4.5 Finishing your setup", " 4 Setting up R Here we setup R, RStudio and anything else we will use in the course. 4.1 Setting up R R is a free, open source, environment for data analysis. It is available as a free binary download for Mac, Linux and Windows. For the more adventorous, it can also be compiled from source. To install R in your computer go to https://cran.r-project.org/index.html and download and install the appropriate binary file. This will install the base R system: the R programming language, a few packages for common data analyses and a development environment. 4.2 Setting up Rstudio We will actually use Rstudio to interact with R. Rstudio is a very powerful application to make data analysis with R easier to do. To install go to https://www.rstudio.com/products/rstudio/download/ and download the appropriate version of Rstudio. 4.3 A first look at Rstudio Let’s take a first look at Rstudio. The first thing you will notice is that Rstudio is divided into panes. Let’s take a look first at the Console. 4.3.1 Interactive Console The most immediate way to interact with R is through the interactive console. Here we can write R instructions to perform our data analyses. We want to start using data so the first instructions we will look at deal with loading data. When you installed R, a few illustrative datasets were installed as well. Let’s take a look at the list of datasets you now have access to. Write the following command in the console This will list names and descriptions of datasets available in your R installation. Let’s try to find out more information about these datasets. In R, the first attempt to get help with something is to use the ? operation. So, to get help about the swiss dataset we can enter the following in the console This will make the documentation for the swiss dataset open in another pane. On your own: Find more information about a different dataset using the ? operator. 4.3.2 Data Viewer According to the documentation we just saw for swiss, this is a data.frame with 47 observations and 6 variables. The data.frame is the basic structure we will use to represent data throughout the course. We will see this again repeatedly, and use a couple of other names (e.g., tibble) to refer to this. Intuitively, you can think of the data.frame like a spreadsheet, with rows representing observations, and columns representing variables that describe those observations. Let’s see what the swiss data looks like using the Rstudio data viewer. The Data Viewer lets you reorder data by the values in a column. It also lets you filter rows of the data by values as well. On your own: Use the Data Viewer to explore another of the datasets you saw listed before. 4.3.3 Names, values and functions Let’s make a very short pause to talk about something you may have noticed. In the console, we’ve now written a few instructions, e.g. View(swiss). Let’s take a closer look at how these instructions are put together. expressions: first of all, we call these instructions expressions, which are just text that R can evaluate into a value. View(swiss) is an expression. values: so, what’s a value? They are numbers, strings, data frames, etc. This is the data we will be working with. The number 2 is a value. So is the string &quot;Hector&quot;. So, what value is produced when R evaluates the expression View(swiss)? Nothing, which we also treat as a value. That wasn’t very interesting, but it does have a side effect: it shows the swiss dataset in the Data viewer. How about a simpler expression: swiss, what value is produced when R evaluates the expression swiss? The data.frame containing that data. Try it out in the console. names: so if swiss isn’t a value, what is it? It is a name. We use these to refer to values. So, when we write the expression swiss, we tell R we want the value referenced by the name swiss, that is, the data itself! functions: Besides numbers, strings, data frames, etc. another important type of value is the function. Functions are a series of instructions that take some input value and produce a different value. The name View refers to the function that takes a data frame as input, and displays it in the Data viewer. Functions are called using the parentheses we saw before: View(swiss), the parentheses say that you are passing input swiss to the function View. We’ll see later how we can write our own functions. 4.3.4 Plotting Next, I want to show the Plots pane in Rstudio. Let’s make a plot using the swiss dataset: It’s not pretty, but it was very easy to produce. There’s a couple of things going on here… plot is a function, it takes two inputs, the data to put in the x and y axes, evaluates to nothing, but creates a plot of the data swiss$Education is how we refer to the Education column in the swiss data frame. On your own: Make a plot using other variables in the swiss dataset. 4.3.5 Editor So far, we’ve made some good progress: we know how to write expressions on the R console so that they are evaluated, we are starting to get a basic understanding of how these expressions are constructed, we can use the Data viewer to explore data frames, and made one plot that was displayed in the Plots pane. To finish this quick tour, I want to look at two more Rstudio panes: the file editor, and the File viewer. As you have noticed, everytime we want to evaluate an expression on the console, we have to write it in. For example, if we want to change the plot we made above to include a different variable, we have to write the whole thing again. Also, what if I forgot what expression I used to make a specific plot? Even better, what if I wanted somebody else to make the plot I just made? By far, one of the biggest advantages of using R over Excel or other similar programs, is that we can write expressions in scripts that are easy to share with others, making analyses easier to reproduce. Let’s write a script that we can use to make the same plot we just made. In the Rstudio menu select File&gt;New File&gt;R Script This will open a tab in the File editor in which we can write expressions: We can then evaluate the expressions in the file one at a time, or all at the same time. We can then save these expressions in a script. In the Rstudio menu select File&gt;Save and save as a text file. The convention is to use the .R or .r file extension, e.g., swiss_plot.r. On your own: Add expressions for additional plots to the script and save again. Run the new expressions. 4.3.6 Files viewer Rstudio includes a Files viewer that you can use to find and load files. You can find the Files near the Plots viewer 4.4 R packages Another of R’s advantages for data analysis is that it has attracted a large number of extremely useful additions provided by users worldwide. These are housed in CRAN. In this course we will make a lot of use of a set of packages bundled together into the tidyverse by Hadley Wickham and others. These packages make preparing, modeling and visualizing certain kinds data (which covers the vast majority of use cases) quite fun and pleasent. There is a webpage for the general tidyverse project: http://tidyverse.org, which includes pages for each of the packages included there. Let’s install the tidyverse into your R environment. There are two ways of installing packages. In the console, you can use the expression: In Rstudio, you can use the Packages tab: On your own: Install the following additional packages which we will use later on: rvest, stringr, and broom. 4.5 Finishing your setup Go to the Google form as instructed and complete your exit ticket. "],
["r-principles.html", "5 R Principles 5.1 Some history 5.2 Additional R resources 5.3 Literate Programming 5.4 A data analysis to get us going 5.5 Getting data 5.6 Variables and Value 5.7 Indexing 5.8 Exploration 5.9 Functions 5.10 A note on data types 5.11 Thinking in vectors 5.12 Lists vs. vectors 5.13 Making the process explicit with pipes", " 5 R Principles Now that we have our tools ready, let’s start doing some analysis. First, let’s go over some principles of R as a data analysis environment. R is a computational environment for data analysis. It is designed around a functional language, as opposed to procedural languages like Java or C, that has desirable properties for the type of operations and workflows that are frequently performed in the course of analyzing datasets. In this exercise we will start learning some of those desirable properties while performing an analysis of a real dataset. 5.1 Some history R is an offspring of S, a language created in AT&amp;T Labs by John Chambers (now at Stanford) and others in 1976 with the goal of creating an environment for statistical computing and data analysis. The standard for the language in current use was settled in 1998. That same year, “S” won the ACM Software System award, awarded to software systems “that have a lasting influence, reflected in contributions to concepts, in commercial acceptance, or both”. In 1991, Robert Gentleman and Ross Ihaka created R to provide an open source implementation of the S language and environment. They also redesigned the language to enforce lexical scoping rules. It has been maintained by the R core group since 1997, and in 2015 an R consortium, including Microsoft, Google, and others, was created. Along with Python it is one of the most popular environments for data analysis (e.g., figure below from KDNuggets 2016 software survey) We use it for this class because we find that besides it being a state-of-the-art data analysis environment, it provides a clean end-to-end platform for teaching material across the data management-modeling-communication spectrum that we study in class. 5.2 Additional R resources Resources for learning and reading about R are listed in our here. Of note are the swirl project and DataCamp’s [introduction to R] course. One of the biggest strengths of the R ecosystem is the variety and quality of packages for data analysis available. R uses a package system (like Python and Ruby for instance). Packages are divided into two classes: base which are packages installed when R is installed, includes packages for basic statistics, computing with probability distributions, plotting and graphics, matrix manipulations and other), all other packages are available in CRAN. We will be using a fair number of these packages through the course of the semester. 5.3 Literate Programming One last note before we get started. R has great support for literate programming, where source code that contains both code, the result of evaluating that code, and text explaining that code co-exist in a single document. This is extremely valuable in data analysis, as many choices made by data analysts are worth explaning in text, and interpretation of the results of analyses can co-exist with the computations used in that analysis. This document you are reading contains both text and code. In class, we will use Rmarkdown for this purpose. 5.4 A data analysis to get us going I’m going to do a very simple analysis of Baltimore crime to show off R. We’ll use data downloaded from Baltimore City’s awesome open data site (this was downloaded a couple of years ago so if you download now, you will get different results). The repository for this particular data is here. https://data.baltimorecity.gov/Crime/BPD-Arrests/3i3v-ibrt 5.5 Getting data We’ve prepared the data previously into a comma-separated value file (.csv file). In this format, each line contains attribute values (separated by commas) for one entity in our dataset. Which we can download and load into our R environment. The read_csv command is part of the readr R package and allows you to read a dataset stored in a csv file. This function is extremely versatile, and you can read more about it by using the standard help system in R: ?read_csv. Now, the result of running calling this function is the data itself, so, by running the function in the console, the result of the function is printed. 5.6 Variables and Value To make use of this dataset we want to assign the result of calling read.csv (i.e., the dataset) to a variable: library(tidyverse) arrest_tab &lt;- read_csv(&quot;data/BPD_Arrests.csv&quot;) ## Parsed with column specification: ## cols( ## arrest = col_integer(), ## age = col_integer(), ## sex = col_character(), ## race = col_character(), ## arrestDate = col_character(), ## arrestTime = col_time(format = &quot;&quot;), ## arrestLocation = col_character(), ## incidentOffense = col_character(), ## incidentLocation = col_character(), ## charge = col_character(), ## chargeDescription = col_character(), ## district = col_character(), ## post = col_integer(), ## neighborhood = col_character(), ## `Location 1` = col_character() ## ) Now we can ask what type of value is stored in the arrest_tab variable: class(arrest_tab) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; The data.frame is a workhorse data structure in R. It encapsulates the idea of entities (in rows) and attribute values (in columns). We can ask other features of this dataset: # This is a comment in R, by the way # How many rows (entities) does this dataset contain? nrow(arrest_tab) ## [1] 104528 # How many columns (attributes)? ncol(arrest_tab) ## [1] 15 # What are the names of those columns? colnames(arrest_tab) ## [1] &quot;arrest&quot; &quot;age&quot; &quot;sex&quot; ## [4] &quot;race&quot; &quot;arrestDate&quot; &quot;arrestTime&quot; ## [7] &quot;arrestLocation&quot; &quot;incidentOffense&quot; &quot;incidentLocation&quot; ## [10] &quot;charge&quot; &quot;chargeDescription&quot; &quot;district&quot; ## [13] &quot;post&quot; &quot;neighborhood&quot; &quot;Location 1&quot; Now, in Rstudio you can view the data frame using View(arrest_tab). 5.7 Indexing A basic operation in data analysis is selecting subsets of a dataset. For that we can use a few alternative options for indexing into datasets. # to obtain the value in the first row, fifth column: arrest_tab[1,5] ## # A tibble: 1 x 1 ## arrestDate ## &lt;chr&gt; ## 1 01/01/2011 # note that indexing in R is 1-based, not 0-based, so the first row is indexed by 1 # now we want to do a bit more, so let&#39;s say we want the value in the fifth column of our dataset for the first 10 rows. For that we can use slice notation: arrest_tab[1:10,5] ## # A tibble: 10 x 1 ## arrestDate ## &lt;chr&gt; ## 1 01/01/2011 ## 2 01/01/2011 ## 3 01/01/2011 ## 4 01/01/2011 ## 5 01/01/2011 ## 6 01/01/2011 ## 7 01/01/2011 ## 8 01/01/2011 ## 9 01/01/2011 ## 10 01/01/2011 # similarly, to obtain the value in the first five columns of the first row arrest_tab[1,1:5] ## # A tibble: 1 x 5 ## arrest age sex race arrestDate ## &lt;int&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; ## 1 11126858 23 B M 01/01/2011 # what is the class of the value when we subset a single column? class(arrest_tab[1:10,5]) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; # what is the class of the value when we subset a single row? class(arrest_tab[1,1:5]) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; # what do we get with this indexing? arrest_tab[1:10,1:5] ## # A tibble: 10 x 5 ## arrest age sex race arrestDate ## &lt;int&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; ## 1 11126858 23 B M 01/01/2011 ## 2 11127013 37 B M 01/01/2011 ## 3 11126887 46 B M 01/01/2011 ## 4 11126873 50 B M 01/01/2011 ## 5 11126968 33 B M 01/01/2011 ## 6 11127041 41 B M 01/01/2011 ## 7 11126932 29 B M 01/01/2011 ## 8 11126940 20 W M 01/01/2011 ## 9 11127051 24 B M 01/01/2011 ## 10 11127018 53 B M 01/01/2011 We can index any set of rows or columns by constructing vectors of integers. In fact, the slice notation : is essentially doing that for a sequence of consecutive indices. You should think of vectors as lists of values with the same class. If we want non-consecutive indices we have other options (e.g., the c function, for “concatenate”) # non-consecutive indices using c arrest_tab[c(2,4,7,10), 1:5] ## # A tibble: 4 x 5 ## arrest age sex race arrestDate ## &lt;int&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; ## 1 11127013 37 B M 01/01/2011 ## 2 11126873 50 B M 01/01/2011 ## 3 11126932 29 B M 01/01/2011 ## 4 11127018 53 B M 01/01/2011 # here&#39;s a fun one, when we call columns for a subset of rows arrest_tab[c(2,4,7,10), ] ## # A tibble: 4 x 15 ## arrest age sex race arrestDate arrestTime arrestLocation ## &lt;int&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; &lt;time&gt; &lt;chr&gt; ## 1 11127013 37 B M 01/01/2011 00:01:00 2000 Wilkens Ave ## 2 11126873 50 B M 01/01/2011 00:04:00 2100 Ashburton St ## 3 11126932 29 B M 01/01/2011 00:05:00 800 N Monroe St ## 4 11127018 53 B M 01/01/2011 00:15:00 3300 Woodland Ave ## # ... with 8 more variables: incidentOffense &lt;fctr&gt;, ## # incidentLocation &lt;chr&gt;, charge &lt;chr&gt;, chargeDescription &lt;chr&gt;, ## # district &lt;chr&gt;, post &lt;int&gt;, neighborhood &lt;chr&gt;, `Location 1` &lt;chr&gt; # there is also the `seq` function, to create sequences arrest_tab[seq(from=1,to=10), seq(1,10)] ## # A tibble: 10 x 10 ## arrest age sex race arrestDate arrestTime arrestLocation ## &lt;int&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; &lt;time&gt; &lt;chr&gt; ## 1 11126858 23 B M 01/01/2011 00:00:00 &lt;NA&gt; ## 2 11127013 37 B M 01/01/2011 00:01:00 2000 Wilkens Ave ## 3 11126887 46 B M 01/01/2011 00:01:00 2800 Mayfield Ave ## 4 11126873 50 B M 01/01/2011 00:04:00 2100 Ashburton St ## 5 11126968 33 B M 01/01/2011 00:05:00 4000 Wilsby Ave ## 6 11127041 41 B M 01/01/2011 00:05:00 2900 Spellman Rd ## 7 11126932 29 B M 01/01/2011 00:05:00 800 N Monroe St ## 8 11126940 20 W M 01/01/2011 00:05:00 5200 Moravia Rd ## 9 11127051 24 B M 01/01/2011 00:07:00 2400 Gainsdbourgh Ct ## 10 11127018 53 B M 01/01/2011 00:15:00 3300 Woodland Ave ## # ... with 3 more variables: incidentOffense &lt;fctr&gt;, ## # incidentLocation &lt;chr&gt;, charge &lt;chr&gt; # that is equivalent to arrest_tab[1:10,1:10] ## # A tibble: 10 x 10 ## arrest age sex race arrestDate arrestTime arrestLocation ## &lt;int&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; &lt;time&gt; &lt;chr&gt; ## 1 11126858 23 B M 01/01/2011 00:00:00 &lt;NA&gt; ## 2 11127013 37 B M 01/01/2011 00:01:00 2000 Wilkens Ave ## 3 11126887 46 B M 01/01/2011 00:01:00 2800 Mayfield Ave ## 4 11126873 50 B M 01/01/2011 00:04:00 2100 Ashburton St ## 5 11126968 33 B M 01/01/2011 00:05:00 4000 Wilsby Ave ## 6 11127041 41 B M 01/01/2011 00:05:00 2900 Spellman Rd ## 7 11126932 29 B M 01/01/2011 00:05:00 800 N Monroe St ## 8 11126940 20 W M 01/01/2011 00:05:00 5200 Moravia Rd ## 9 11127051 24 B M 01/01/2011 00:07:00 2400 Gainsdbourgh Ct ## 10 11127018 53 B M 01/01/2011 00:15:00 3300 Woodland Ave ## # ... with 3 more variables: incidentOffense &lt;fctr&gt;, ## # incidentLocation &lt;chr&gt;, charge &lt;chr&gt; # with the `seq` function you can do more sophisticated things like select only entries in odd rows (1,3,5,7...) head(arrest_tab[seq(from=1,to=nrow(arrest_tab),by=2), ]) ## # A tibble: 6 x 15 ## arrest age sex race arrestDate arrestTime arrestLocation ## &lt;int&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; &lt;time&gt; &lt;chr&gt; ## 1 11126858 23 B M 01/01/2011 00:00:00 &lt;NA&gt; ## 2 11126887 46 B M 01/01/2011 00:01:00 2800 Mayfield Ave ## 3 11126968 33 B M 01/01/2011 00:05:00 4000 Wilsby Ave ## 4 11126932 29 B M 01/01/2011 00:05:00 800 N Monroe St ## 5 11127051 24 B M 01/01/2011 00:07:00 2400 Gainsdbourgh Ct ## 6 11127057 28 B M 01/01/2011 00:15:00 3300 Woodland Ave ## # ... with 8 more variables: incidentOffense &lt;fctr&gt;, ## # incidentLocation &lt;chr&gt;, charge &lt;chr&gt;, chargeDescription &lt;chr&gt;, ## # district &lt;chr&gt;, post &lt;int&gt;, neighborhood &lt;chr&gt;, `Location 1` &lt;chr&gt; Now, since columns have names, we can also use strings (and vectors of strings) to index data frames. # single column arrest_tab[1:10, &quot;age&quot;] ## # A tibble: 10 x 1 ## age ## &lt;int&gt; ## 1 23 ## 2 37 ## 3 46 ## 4 50 ## 5 33 ## 6 41 ## 7 29 ## 8 20 ## 9 24 ## 10 53 # multiple columns arrest_tab[1:10, c(&quot;age&quot;, &quot;sex&quot;, &quot;race&quot;)] ## # A tibble: 10 x 3 ## age sex race ## &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; ## 1 23 B M ## 2 37 B M ## 3 46 B M ## 4 50 B M ## 5 33 B M ## 6 41 B M ## 7 29 B M ## 8 20 W M ## 9 24 B M ## 10 53 B M If we wanted a single named column from a data frame there’s a special operator $ to index: # first ten values of the age column arrest_tab$age[1:10] ## [1] 23 37 46 50 33 41 29 20 24 53 # EXERCISE # try using three different ways of selecting rows 20 to 30 # of the &quot;sex&quot; column In addition to integer indices or names, we can use vectors of logical values for indexing. # rows 2,4,7 and 10 using logical indices arrest_tab[c(FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,rep(FALSE,nrow(arrest_tab)-10)),] ## # A tibble: 4 x 15 ## arrest age sex race arrestDate arrestTime arrestLocation ## &lt;int&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; &lt;time&gt; &lt;chr&gt; ## 1 11127013 37 B M 01/01/2011 00:01:00 2000 Wilkens Ave ## 2 11126873 50 B M 01/01/2011 00:04:00 2100 Ashburton St ## 3 11126932 29 B M 01/01/2011 00:05:00 800 N Monroe St ## 4 11127018 53 B M 01/01/2011 00:15:00 3300 Woodland Ave ## # ... with 8 more variables: incidentOffense &lt;fctr&gt;, ## # incidentLocation &lt;chr&gt;, charge &lt;chr&gt;, chargeDescription &lt;chr&gt;, ## # district &lt;chr&gt;, post &lt;int&gt;, neighborhood &lt;chr&gt;, `Location 1` &lt;chr&gt; # now here&#39;s a fun one, if we only wanted odd rows head(arrest_tab[c(TRUE,FALSE),]) ## # A tibble: 6 x 15 ## arrest age sex race arrestDate arrestTime arrestLocation ## &lt;int&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; &lt;time&gt; &lt;chr&gt; ## 1 11126858 23 B M 01/01/2011 00:00:00 &lt;NA&gt; ## 2 11126887 46 B M 01/01/2011 00:01:00 2800 Mayfield Ave ## 3 11126968 33 B M 01/01/2011 00:05:00 4000 Wilsby Ave ## 4 11126932 29 B M 01/01/2011 00:05:00 800 N Monroe St ## 5 11127051 24 B M 01/01/2011 00:07:00 2400 Gainsdbourgh Ct ## 6 11127057 28 B M 01/01/2011 00:15:00 3300 Woodland Ave ## # ... with 8 more variables: incidentOffense &lt;fctr&gt;, ## # incidentLocation &lt;chr&gt;, charge &lt;chr&gt;, chargeDescription &lt;chr&gt;, ## # district &lt;chr&gt;, post &lt;int&gt;, neighborhood &lt;chr&gt;, `Location 1` &lt;chr&gt; The last example shows one of the most common gotchas in R. Indices are recycled. For instance if selecting rows, if you pass a logical vector that’s shorter than the number of rows in the data frame, the vector will be recycled as many times as necessary to match the number of rows in the dataset. Now, why is this useful, because a pithy index vector can let you select easily. Why is this bad, because errors in code can go easily unnoticed. So in this case, the price of ease of use is paid by the programmer by having to think a lot more carefully about their code (this is a theme in R programming…) The utility of logical indexing is that now we can select rows based on a property of its values for a given column # select rows for entities younger than 21 years old head(arrest_tab[arrest_tab$age &lt; 21, ]) ## # A tibble: 6 x 15 ## arrest age sex race arrestDate arrestTime arrestLocation ## &lt;int&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; &lt;time&gt; &lt;chr&gt; ## 1 11126940 20 W M 01/01/2011 00:05:00 5200 Moravia Rd ## 2 11126942 20 B M 01/01/2011 01:22:00 1900 Ashburton Ave ## 3 11126941 20 W M 01/01/2011 02:00:00 300 S Bentalou St ## 4 11126955 20 B M 01/01/2011 02:20:00 900 Myrtle Ave ## 5 11127139 19 W M 01/01/2011 02:22:00 4500 Erdman Ave ## 6 11127003 20 B F 01/01/2011 02:49:00 2400 Brentwood St ## # ... with 8 more variables: incidentOffense &lt;fctr&gt;, ## # incidentLocation &lt;chr&gt;, charge &lt;chr&gt;, chargeDescription &lt;chr&gt;, ## # district &lt;chr&gt;, post &lt;int&gt;, neighborhood &lt;chr&gt;, `Location 1` &lt;chr&gt; # notice that the value of expression `arrest_tab$age &lt; 21` # is a logical vector # select entities (arrests) occuring in Mount Washington, # a specific neighborhood in Baltimore head(arrest_tab[arrest_tab$neighborhood == &quot;Mount Washington&quot;,]) ## # A tibble: 6 x 15 ## arrest age sex race arrestDate arrestTime arrestLocation ## &lt;int&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; &lt;time&gt; &lt;chr&gt; ## 1 NA NA NA NA &lt;NA&gt; NA &lt;NA&gt; ## 2 NA NA NA NA &lt;NA&gt; NA &lt;NA&gt; ## 3 NA NA NA NA &lt;NA&gt; NA &lt;NA&gt; ## 4 NA NA NA NA &lt;NA&gt; NA &lt;NA&gt; ## 5 NA NA NA NA &lt;NA&gt; NA &lt;NA&gt; ## 6 NA NA NA NA &lt;NA&gt; NA &lt;NA&gt; ## # ... with 8 more variables: incidentOffense &lt;fctr&gt;, ## # incidentLocation &lt;chr&gt;, charge &lt;chr&gt;, chargeDescription &lt;chr&gt;, ## # district &lt;chr&gt;, post &lt;int&gt;, neighborhood &lt;chr&gt;, `Location 1` &lt;chr&gt; # how about arrests where subjects are under 21 in Mount Washington? # use a logical `and` operator indices &lt;- arrest_tab$age &lt; 21 &amp; arrest_tab$neighborhood == &quot;Mount Washington&quot; 5.8 Exploration R has built-in functions that help easily obtain summary information about datasets. For instance: summary(arrest_tab$sex) ## A B H I U W NA&#39;s ## 242 87268 1 218 1749 15048 2 summary(arrest_tab$race) ## F M NA&#39;s ## 19431 85095 2 # well that seems problematic # let&#39;s rename columns to correct that colnames(arrest_tab)[3:4] &lt;- c(&quot;race&quot;, &quot;sex&quot;) We can also ask other useful type of summaries # What is the average age in arrests? mean(arrest_tab$age) ## [1] 33.19639 # Median age? median(arrest_tab$age) ## [1] 30 # what types of offenses are there summary(arrest_tab$incidentOffense) ## Unknown Offense 87-Narcotics ## 38649 24744 ## 4E-Common Assault 87O-Narcotics (Outside) ## 6739 6515 ## 97-Search &amp; Seizure 79-Other ## 3670 3461 ## 24-Towed Vehicle 6C-Larceny- Shoplifting ## 2994 1849 ## 4C-Agg. Asslt.- Oth. 55A-Prostitution ## 1556 1398 ## 4B-Agg. Asslt.- Cut 55-Disorderly Person ## 1195 923 ## 115-Trespassing 5A-Burg. Res. (Force) ## 871 847 ## 75-Destruct. Of Property 4D-Agg. Asslt.- Hand ## 686 618 ## 61-Person Wanted On War 3B-Robb Highway (Ua) ## 482 410 ## 54-Armed Person 7A-Stolen Auto ## 394 392 ## 4A-Agg. Asslt.- Gun 6D-Larceny- From Auto ## 356 336 ## 6J-Larceny- Other 3AF-Robb Hwy-Firearm ## 312 277 ## 49-Family Disturbance 26-Recovered Vehicle ## 253 249 ## 6G-Larceny- From Bldg. 20A-Followup ## 248 246 ## 78-Gambling 5D-Burg. Oth. (Force) ## 219 196 ## 3K-Robb Res. (Ua) 111-Protective Order ## 176 152 ## 4F-Assault By Threat 109-Loitering ## 152 131 ## 117-Fto 5C-Burg. Res. (Noforce) ## 130 122 ## 3AK-Robb Hwy-Knife 5B-Burg. Res. (Att.) ## 102 102 ## 81-Recovered Property 108-Liquor Law/Open Container ## 94 92 ## 3D-Robb Comm. (Ua) 2A-Rape (Force) ## 92 89 ## 6E-Larceny- Auto Acc 112-Traffic Related Incident ## 85 81 ## 23-Unauthorized Use 88-Unfounded Call ## 81 80 ## 3AO-Robb Hwy-Other Wpn 7C-Stolen Veh./Other ## 79 78 ## 2H-Indecent Exp. 1A-Murder ## 72 64 ## 71-Sex Offender Registry 48-Involuntary Detention ## 64 57 ## 114-Hindering 3AJF-Robb Carjack-Firearm ## 56 56 ## 2F-Placing Hands 73-False Pretense ## 54 54 ## 6B-Larceny- Purse Snatch 95-Exparte ## 51 51 ## 3CF-Robb Comm-Firearm 3JF-Robb Residence-Firearm ## 43 43 ## 56-Missing Person 98-Child Neglect ## 41 41 ## 3P-Robb Misc. (Ua) 58-Injured Person ## 35 35 ## 85-Mental Case 3BJ-Robb Carjack(Ua) ## 34 33 ## 5F-Burg. Oth. (Noforce) 6F-Larceny- Bicycle ## 31 31 ## 2G-Sodomy/Perverson 3JK-Robb Residence-Knife ## 30 30 ## 3CK-Robb Comm-Knife 80-Lost Property ## 25 25 ## 2B-Rape (Attempt) 29-Driving While Intox. ## 21 20 ## 3NF-Robb Misc-Firearm 5E-Burg. Oth. (Att.) ## 20 18 ## 2D-Statutory Rape 3JO-Robb Residence-Other Wpn ## 17 17 ## 67-Child Abuse-Physical 103-Dead On Arrival ## 17 15 ## 3CO-Robb Comm-Other Wpn 3NK-Robb Misc-Knife ## 15 15 ## 113-Littering 39-Fire ## 14 14 ## 76-Child Abuse-Sexual 8AO-Arson Sin Res Str-Occ ## 14 14 ## 96-Stop &amp; Frisk 116-Public Urination / Defecation ## 14 13 ## 110-Summons Served 20H-Traffic Control ## 12 11 ## 3AJK-Robb Carjack-Knife 3GF-Robb Conv Store-Firearm ## 11 11 ## 106-Custody Dispute 52A-Animal Cruelty ## 10 10 ## 70A-Ill. Dumping 83-Discharging Firearm ## 10 10 ## 3H-Robb Conv. Stor.(Ua) 3NO-Robb Misc-Other Wpn ## 9 8 ## 93-Abduction - Other (Other) ## 8 101 # what does summary looks like for continuous attributes? summary(arrest_tab$age) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0 23.0 30.0 33.2 43.0 87.0 Combining this type of summary with our indexing strategies we learned previously we can ask more specific questions # What is the average age for arrests in Mount Washington? mount_washington_index &lt;- arrest_tab$neighborhood == &quot;Mount Washington&quot; mean(arrest_tab$age[mount_washington_index], na.rm=TRUE) ## [1] 31.10345 # How about the number of arrests in Mount Washington _stratified_ by race and sex? table(arrest_tab$race[mount_washington_index], arrest_tab$sex[mount_washington_index]) ## ## F M ## A 0 0 ## B 4 14 ## H 0 0 ## I 0 0 ## U 0 0 ## W 2 9 # how about a graphical summary of arrest ages in Mount Washington? # we&#39;ll use a boxplot boxplot(arrest_tab$age[mount_washington_index]) # can we do the same stratified by sex? boxplot(arrest_tab$age[mount_washington_index]~arrest_tab$sex[mount_washington_index]) This used a very useful notation in R: the tilde, ~ which we will encounter in a few different places. One way of thinking about that abstractly is, do something with this attribute, as a function (or depending on, stratified by, conditioned on) this other attribute. For instance, “plot age as a function of sex” in our example. Let’s write code that’s a little cleaner for that last plot, and let’s also make the plot a bit more useful by adding a title and axis labels: mount_washington_tab &lt;- arrest_tab[mount_washington_index,] boxplot(mount_washington_tab$age~mount_washington_tab$sex, main=&quot;Mt. Washington&quot;, xlab=&quot;Sex&quot;, ylab=&quot;Arrest Age&quot;) Here’s one more useful plot: barplot(table(mount_washington_tab$race), xlab=&quot;Number of Arrests&quot;, ylab=&quot;Race&quot;) 5.9 Functions Now suppose we wanted to do a similar analysis for other neighborhoods. In that case we should encapsulate the summaries and plots we want to do in a function: analyze_neighborhood &lt;- function(neighborhood) { neighborhood_index &lt;- arrest_tab$neighborhood == neighborhood neighborhood_tab &lt;- arrest_tab[neighborhood_index,] boxplot(neighborhood_tab$age~neighborhood_tab$sex, main = neighborhood, xlab = &quot;Sex&quot;, ylab=&quot;Arrest Age&quot;) barplot(table(neighborhood_tab$race), main = neighborhood, xlab = &quot;Race&quot;, ylab=&quot;Number of Arrests&quot;) } Now we can use that function to make our plots for specific neighborhoods analyze_neighborhood(&quot;Mount Washington&quot;) analyze_neighborhood(&quot;Hampden&quot;) 5.10 A note on data types This dataset contains data of types commonly found in data analyses Numeric (continuous): A numeric measurement (e.g., height) Numeric (discrete): Usually obtained from counting, think only integers (e.g., age which is measured in years) Categorical: One of a possible set of values (e.g., sex) Datetime: Date and time of some event or observation (e.g., arrestDate, arrestTime) geolocation: Latitude and Longitude of some event or observation (e.g., Location.) The distinction between continuous and discrete is a bit tricky since measurements that have finite precision must be discrete. So, the difference really comes up when we build statistical models of datasets for analysis. For now, think of discrete data as the result of counting, and continuous data the result of some physical measurement. We said that R is designed for data analysis. My favorite example of how that manifests itself is the factor datatype. If you look at your dataset now, arrest_tab$sex is a vector of strings: class(arrest_tab$sex) ## [1] &quot;factor&quot; summary(arrest_tab$sex) ## F M NA&#39;s ## 19431 85095 2 However, as a measurement, or attribute, it should only take one of two values (or three depending on how you record missing, unknown or unspecified). So, in R, that categorical data type is called a factor. Notice what the summary function does after turning the sex attribute into a factor: arrest_tab$sex &lt;- factor(arrest_tab$sex) summary(arrest_tab$sex) ## F M NA&#39;s ## 19431 85095 2 This distinction shows up in many other places where functions have very different behavior when called on a vector of strings and when called on a factor (e.g., functions that make plots, or functions that learn statistical models). One last note, the possible values a factor can take are called levels: levels(arrest_tab$sex) ## [1] &quot;F&quot; &quot;M&quot; Exercise: you should transform the race attribute into a factor as well. How many levels does it have? 5.11 Thinking in vectors In data analysis the vector is probably the most fundamental data type (other than basic numbers, strings, etc.). Why? Consider getting data about one attribute, say height, for a group of people. What do you get, an array of numbers, all in the same unit (say feet, inches or centimeters). How about their name? Then you get an array of strings. Abstractly, we think of vectors as arrays of values, all of the same class or datatype. In our dataset, each column, corresponding to an attribute, is a vector: # the &#39;str&#39; function gives a bit more low-level information about objects str(arrest_tab$Location) ## Warning: Unknown or uninitialised column: &#39;Location&#39;. ## NULL R (and other data analysis languages) are designed to operate on vectors easily. For example, frequently we want to do some kind of transformation to a data attribute, say record age in months rather than years. Then we would perform the same operation for every value in the corresponding vector: age_in_months &lt;- arrest_tab$age * 12 In a language that doesn’t support this type of vectorized operation, you would use a loop, or similar construct, to perform this operation. Another type of transformation frequently done is to combine attributes into a single attribute. Suppose we wanted to combine the arrestLocation and neighborhood attributes into an address attribute: # remember you can always find out what a function does by using ?paste head(paste(arrest_tab$arrestLocation, arrest_tab$neighborhood, sep=&quot;, &quot;)) ## [1] &quot;NA, NA&quot; ## [2] &quot;2000 Wilkens Ave, Carrollton Ridge&quot; ## [3] &quot;2800 Mayfield Ave, Belair-Edison&quot; ## [4] &quot;2100 Ashburton St, Panway/Braddish Avenue&quot; ## [5] &quot;4000 Wilsby Ave, Pen Lucy&quot; ## [6] &quot;2900 Spellman Rd, Cherry Hill&quot; Here the paste function concatenates strings element-wise: the first string in arrestLocation is concatenated with the first string in neighborhood, etc. Arithmetic operations have the same element-wise operation: # add first 10 odd numbers to first 10 even numbers seq(1, 20, by=2) + seq(2, 20, by=2) ## [1] 3 7 11 15 19 23 27 31 35 39 5.12 Lists vs. vectors We saw that vectors are arrays of values, all of the same class. R also allows arrays of values that have different class or datatype. These are called lists. Here is a list containing a string, and a couple of numbers: my_list &lt;- list(&quot;Hector&quot;, 40, 71) my_list ## [[1]] ## [1] &quot;Hector&quot; ## ## [[2]] ## [1] 40 ## ## [[3]] ## [1] 71 Indexing in lists uses different syntax from the indexing we saw before. To index an element in a list we would use a double-bracket [[. my_list[[1]] ## [1] &quot;Hector&quot; In contrast, the single bracket [ indexes a part of the list, and thus returns another list. my_list[1] ## [[1]] ## [1] &quot;Hector&quot; That way we can use slice notation and other operations we saw when indexing vectors as before, but we get lists as results. my_list[1:2] ## [[1]] ## [1] &quot;Hector&quot; ## ## [[2]] ## [1] 40 List elements can have names as well: named_list &lt;- list(person=&quot;Hector&quot;, age=40, height=71) named_list ## $person ## [1] &quot;Hector&quot; ## ## $age ## [1] 40 ## ## $height ## [1] 71 Which we can use to index elements as well (both with [[ and $) named_list[[&quot;person&quot;]] ## [1] &quot;Hector&quot; named_list$person ## [1] &quot;Hector&quot; Lists can hold arbitrary objects as elements. For example you can have a vector of strings as an element in a list my_list &lt;- list(person=c(&quot;Hector&quot;, &quot;Ringo&quot;, &quot;Paul&quot;, &quot;John&quot;), 40, 71) my_list ## $person ## [1] &quot;Hector&quot; &quot;Ringo&quot; &quot;Paul&quot; &quot;John&quot; ## ## [[2]] ## [1] 40 ## ## [[3]] ## [1] 71 Now, we come to a momentous occassion in understanding R. data.frames are special instances of lists! But, in this case, every element in the list is a vector, and all vectors have exactly the same length. So arrest_tab$age indexes the named element age in the list arrest_tab! The pattern of applying functions to entries in vectors also holds for elements in lists. So, if we want to calculate smallest value for every attribute in our dataset, we could do something like this: sapply(arrest_tab, function(v) sort(v)[1]) ## arrest ## &quot;11126858&quot; ## age ## &quot;0&quot; ## race ## &quot;1&quot; ## sex ## &quot;1&quot; ## arrestDate ## &quot;01/01/2011&quot; ## arrestTime ## &quot;0&quot; ## arrestLocation ## &quot;0 20Th St&quot; ## incidentOffense ## &quot;1&quot; ## incidentLocation ## &quot;*** District Detail ***&quot; ## charge ## &quot;1 0002&quot; ## chargeDescription ## &quot;Abduct Child Under 12 || Abduct Child Under 12&quot; ## district ## &quot;CENTRAL&quot; ## post ## &quot;111&quot; ## neighborhood ## &quot;Abell&quot; ## Location 1 ## &quot;(39.2000327685, -76.5555163146)&quot; 5.13 Making the process explicit with pipes We’ve discussed the idea of thinking about data analysis work in terms of “pipelines”, where we start from data of a certain shape (e.g., a data.frame) and apply transformations (functions) to obtain data that contains the computation we want. Consider the following example seen in class: What is the mean age of males arrested in the SOUTHERN district? We can frame the answer to this question as a series of data transformations to get the answer we are looking for: # filter data to observations we need index_vector &lt;- arrest_tab$sex == &quot;M&quot; &amp; arrest_tab$district == &quot;SOUTHERN&quot; tmp &lt;- arrest_tab[index_vector,] # select the attribute/column we need tmp &lt;- tmp[[&quot;age&quot;]] # compute statistic required mean(tmp, na.rm=TRUE) ## [1] 32.28481 Let’s rewrite this using functions to illustrate the point filter_data &lt;- function(data) { index_vector &lt;- data$sex == &quot;M&quot; &amp; data$district == &quot;SOUTHERN&quot; data[index_vector,] } select_column &lt;- function(data, column) { data[[column]] } tmp &lt;- filter_data(arrest_tab) tmp &lt;- select_column(tmp, &quot;age&quot;) mean(tmp, na.rm=TRUE) ## [1] 32.28481 So, this pattern of data–&gt;transform–&gt;data becomes clearer when written that way. The dplyr package introduces syntactic sugar to make this explicit. We can write the above snippet using the “pipe” operator %&gt;%: arrest_tab %&gt;% filter_data() %&gt;% select_column(&quot;age&quot;) %&gt;% mean(na.rm=TRUE) ## [1] 32.28481 The %&gt;% binary operator takes the value to its left and inserts it as the first argument of the function call to its right. So the expression LHS %&gt;% f(another_argument) is equivalent to the expression f(LHS, another_argument). We will see this pattern extensively in class because it explicitly presents the way we want to organize many of our data analysis tasks. "],
["ingesting-data.html", "6 Ingesting data", " 6 Ingesting data How to scrape data in R, and an introduction to R itself. "],
["tidying-data.html", "7 Tidying data", " 7 Tidying data What is tidy data and how to manipulate it using dplyr. "],
["visualizing-data.html", "8 Visualizing data", " 8 Visualizing data How to visualize data using ggplot2. "],
["capstone-project-1.html", "9 Capstone Project 1", " 9 Capstone Project 1 A capstone project for the scrape-&gt;tidy-&gt;visualize workflow. "],
["social-media-analysis.html", "10 Social Media Analysis", " 10 Social Media Analysis An analysis of twitter text and network with an introduction to basic statistical modeling. "],
["survey-analysis.html", "11 Survey Analysis", " 11 Survey Analysis A survey analysis to describe slightly more complex stat things. "],
["day-2-capstone-project.html", "12 Day 2 Capstone Project", " 12 Day 2 Capstone Project A capstone project to practice the scrape-&gt;tidy-&gt;model-&gt;visualize workflow. "],
["publishing-analyses-with-r.html", "13 Publishing Analyses with R", " 13 Publishing Analyses with R Publishing stuff with R. Rmarkdown, bookdown and shiny. "],
["teaching-with-r.html", "14 Teaching with R", " 14 Teaching with R How to use R in teaching. "],
["day-3-capstone-project.html", "15 Day 3 Capstone Project", " 15 Day 3 Capstone Project A final capstone project putting everything together. "]
]
